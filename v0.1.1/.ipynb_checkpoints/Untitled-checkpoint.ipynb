{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56540bd-d0ec-4f60-b6e4-5add6acb6b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from process_text import process_text\n",
    "import utilities\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e9f3f3-04b1-4b1f-8304-0e7f7848aab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # load the required NLTK data and resources\n",
    "    utilities.download(\"punkt\")\n",
    "    utilities.download('universal_tagset')\n",
    "\n",
    "    # read the requirements.csv file into a dataframe\n",
    "    df = pd.read_csv('./assets/csv/requirements.csv')\n",
    "\n",
    "    # get the sentences and labels from the dataframe\n",
    "    sentences = df['text'].tolist()\n",
    "    labels = df['label'].tolist()\n",
    "\n",
    "    # use the list of sentences to call the process_text function \n",
    "    # and write the result to a csv file\n",
    "    df_results = pd.DataFrame(columns=['label', 'sentence', 'syntax'])\n",
    "    #for i, sentence in enumerate(sentences):\n",
    "    #    print(i)\n",
    "    #    entities = process_text(sentence)\n",
    "    #    syntax = ''\n",
    "    #    for entity in entities:\n",
    "    #        syntax = syntax + entity[0] + ' '\n",
    "    #    df_temp = pd.DataFrame({'label': [labels[i]], 'sentence': [sentence], 'syntax': [syntax]})\n",
    "    #    df_results = pd.concat([df_results, df_temp], ignore_index=True)\n",
    "    #df_results.to_csv('./assets/csv/results.csv', index=False)\n",
    "\n",
    "    # Read the CSV file into a dataframe\n",
    "    df = pd.read_csv('./assets/csv/results.csv')\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    req_train, req_test = train_test_split(df, test_size=0.2)\n",
    "\n",
    "    # Define the pipeline for the RandomForestClassifier model\n",
    "    pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer()),\n",
    "        ('clf', RandomForestClassifier())\n",
    "    ])\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    pipeline.fit(req_train['syntax'], req_train['label'])\n",
    "\n",
    "    # Evaluate the model on the test data\n",
    "    y_pred = pipeline.predict(req_test['syntax'])\n",
    "\n",
    "    acc = accuracy_score(req_test['label'], y_pred)\n",
    "    prec = precision_score(req_test['label'], y_pred, average=None)\n",
    "    mc = confusion_matrix(y_pred, req_test['label'])\n",
    "\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(\"Precision:\", prec)\n",
    "    print(\"Confusion matrix:\\n\", mc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed88eb7-ee0f-4006-bd4e-3daf8c2e03a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels for the input examples\n",
    "input_examples = [\n",
    "    \"The system must be able to handle an increase in users and data without significant performance degradation.\",\n",
    "    \"The software must use secure protocols for transmitting data.\",\n",
    "    \"The website must be accessible for users with disabilities.\"\n",
    "]\n",
    "for example in input_examples:\n",
    "    syntax = ' '.join([entity[0] for entity in process_text(example)])\n",
    "    label = pipeline.predict([syntax])[0]\n",
    "    print(f\"Input example: {example}\")\n",
    "    print(f\"Predicted label: {label}\")\n",
    "    print(f\"Precision for label: {precision[label]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b22274-457a-4486-8a06-a6221073ad66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
